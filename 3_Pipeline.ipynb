{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d38afa91",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\virtualenv\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import plotly.express as px \n",
    "import pandas as pd \n",
    "import cv2 \n",
    "import os \n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, Activation, Dropout, Flatten, Dense, Dropout, LayerNormalization\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle \n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#added import for sgd\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "# for Landmark detection\n",
    "# import dlib\n",
    "import dlib\n",
    "from imutils.face_utils import FaceAligner\n",
    "from imutils.face_utils import rect_to_bb\n",
    "\n",
    "import imutils\n",
    "\n",
    "from tensorflow.keras.metrics import Precision, Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a16c2e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = r'/age and gender prediction/project/data/imdb_crop/08/nm0000408_rm725519360_1952-8-19_2002.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39ebd063",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
     ]
    }
   ],
   "source": [
    "adience_model = tf.keras.models.load_model(\"gender_26nov_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d7feed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "img= cv2.imread(image_path, 1)\n",
    "\n",
    "denoised_image = cv2.fastNlMeansDenoisingColored(img, None, 5, 6, 7, 21)\n",
    "\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor('shape_predictor_68_face_landmarks.dat')\n",
    "fa = FaceAligner(predictor, desiredFaceWidth=256)\n",
    "    \n",
    "gray = cv2.cvtColor(denoised_image, cv2.COLOR_BGR2GRAY)\n",
    "# Detect the face\n",
    "rects = detector(gray, 1)\n",
    "# Detect landmarks for each face\n",
    "try: \n",
    "    for rect in rects:\n",
    "        faceAligned = fa.align(img, gray, rect)\n",
    "\n",
    "    gray1 = cv2.cvtColor(faceAligned, cv2.COLOR_BGR2GRAY)\n",
    "    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "    faces = face_cascade.detectMultiScale(gray1, 1.3, 5)\n",
    "\n",
    "    try:\n",
    "        for (x,y,w,h) in faces:\n",
    "            # for putting rectangle on face\n",
    "            # cv2.rectangle(faceAligned, (x,y), (x+w, y+h), (0, 255, 0),3)\n",
    "            faceAligned_final = faceAligned[y:y+h, x:x+w]\n",
    "            # cv2.imwrite(imageP , roi_color)\n",
    "    except:\n",
    "        print('No face Detected')\n",
    "except:\n",
    "    print('No face Detected')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "51c36d01",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "faceAligned_final = cv2.resize(faceAligned_final, (227, 227))\n",
    "\n",
    "img_batch = np.expand_dims(faceAligned_final, axis = 0)\n",
    "img_batch = img_batch/255.\n",
    "result = np.argmax(adience_model.predict(img_batch))\n",
    "print(result)\n",
    "# if result == 1:\n",
    "#     print(f\"Predicted gender: Male\")\n",
    "# else:\n",
    "#     print(f\"Predicted gender: Female\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c991bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "img= cv2.imread(image_path)\n",
    "cv2.imshow('image', img)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a593a038",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2109b4f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a5d7f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba10f865",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa47ce4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
