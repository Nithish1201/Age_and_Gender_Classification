{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b191786e",
   "metadata": {},
   "source": [
    "# Age Classification Using Facial Images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f0339d9",
   "metadata": {},
   "source": [
    "#### Import Statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75d0d06c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\virtualenv\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import plotly.express as px \n",
    "import pandas as pd \n",
    "import cv2 \n",
    "import os \n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, Activation, Dropout, Flatten, Dense, Dropout, LayerNormalization\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle \n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "#added import for sgd\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "# import dlib\n",
    "import dlib\n",
    "\n",
    "import dlib\n",
    "\n",
    "from imutils.face_utils import FaceAligner\n",
    "from imutils.face_utils import rect_to_bb\n",
    "\n",
    "import imutils\n",
    "\n",
    "from tensorflow.keras.metrics import Precision, Recall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a290bb78",
   "metadata": {},
   "source": [
    "## Data Retrival and Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32dc1b92",
   "metadata": {},
   "source": [
    "#### Converting the txt data to a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b3fdc40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>path</th>\n",
       "      <th>AgeRange</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30</td>\n",
       "      <td>male</td>\n",
       "      <td>imdb_crop/99/nm0625099_rm316640512_1974-11-2_2...</td>\n",
       "      <td>Youth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27</td>\n",
       "      <td>male</td>\n",
       "      <td>imdb_crop/90/nm0004790_rm365789952_1976-8-23_2...</td>\n",
       "      <td>Youth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23</td>\n",
       "      <td>male</td>\n",
       "      <td>imdb_crop/68/nm0356468_rm3801258496_1975-8-4_1...</td>\n",
       "      <td>Youth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29</td>\n",
       "      <td>male</td>\n",
       "      <td>imdb_crop/58/nm1864458_rm1663605504_1975-9-17_...</td>\n",
       "      <td>Youth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24</td>\n",
       "      <td>male</td>\n",
       "      <td>wiki_crop/56/29835356_1989-07-25_2014.jpg</td>\n",
       "      <td>Youth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211096</th>\n",
       "      <td>48</td>\n",
       "      <td>male</td>\n",
       "      <td>imdb_crop/81/nm0000381_rm1343402752_1962-7-19_...</td>\n",
       "      <td>Adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211097</th>\n",
       "      <td>42</td>\n",
       "      <td>male</td>\n",
       "      <td>imdb_crop/62/nm1101562_rm723357184_1959-10-7_2...</td>\n",
       "      <td>Adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211098</th>\n",
       "      <td>29</td>\n",
       "      <td>female</td>\n",
       "      <td>wiki_crop/22/3571322_1977-01-31_2007.jpg</td>\n",
       "      <td>Youth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211099</th>\n",
       "      <td>57</td>\n",
       "      <td>male</td>\n",
       "      <td>imdb_crop/16/nm0000616_rm2154482176_1956-4-18_...</td>\n",
       "      <td>Old</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211100</th>\n",
       "      <td>15</td>\n",
       "      <td>female</td>\n",
       "      <td>imdb_crop/89/nm0094789_rm991411456_1967-5-31_1...</td>\n",
       "      <td>Youth</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>211101 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        age  gender                                               path  \\\n",
       "0        30    male  imdb_crop/99/nm0625099_rm316640512_1974-11-2_2...   \n",
       "1        27    male  imdb_crop/90/nm0004790_rm365789952_1976-8-23_2...   \n",
       "2        23    male  imdb_crop/68/nm0356468_rm3801258496_1975-8-4_1...   \n",
       "3        29    male  imdb_crop/58/nm1864458_rm1663605504_1975-9-17_...   \n",
       "4        24    male          wiki_crop/56/29835356_1989-07-25_2014.jpg   \n",
       "...     ...     ...                                                ...   \n",
       "211096   48    male  imdb_crop/81/nm0000381_rm1343402752_1962-7-19_...   \n",
       "211097   42    male  imdb_crop/62/nm1101562_rm723357184_1959-10-7_2...   \n",
       "211098   29  female           wiki_crop/22/3571322_1977-01-31_2007.jpg   \n",
       "211099   57    male  imdb_crop/16/nm0000616_rm2154482176_1956-4-18_...   \n",
       "211100   15  female  imdb_crop/89/nm0094789_rm991411456_1967-5-31_1...   \n",
       "\n",
       "       AgeRange  \n",
       "0         Youth  \n",
       "1         Youth  \n",
       "2         Youth  \n",
       "3         Youth  \n",
       "4         Youth  \n",
       "...         ...  \n",
       "211096    Adult  \n",
       "211097    Adult  \n",
       "211098    Youth  \n",
       "211099      Old  \n",
       "211100    Youth  \n",
       "\n",
       "[211101 rows x 4 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('cleaned_IMDB_WIKI_non_gray.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0569d13",
   "metadata": {},
   "source": [
    "#### Dropping null values and resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7147b8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()\n",
    "df = df.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc85dc3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(211101, 4)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41fc3b7e",
   "metadata": {},
   "source": [
    "#### Using the details of dataframe to get the image path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ae4f34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['image_path'] = '/age and gender prediction/project/data/'+ df['path']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d8128b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Youth    104604\n",
       "Adult     83935\n",
       "Old       18921\n",
       "Kid        3641\n",
       "Name: AgeRange, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['AgeRange'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a0504c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = df[['AgeRange', 'age', 'gender', 'image_path']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d25b8cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "del df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d004603",
   "metadata": {},
   "source": [
    "#### Using LabelEncoder to obtain targets in integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a50db367",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder \n",
    "le = LabelEncoder()\n",
    "new_df['AgeRange'] = le.fit_transform(new_df['AgeRange'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73fbaa8f",
   "metadata": {},
   "source": [
    "#### Dumping the same for future usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "03b6ba42",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('imdbwiki_age_encoder.pkl','wb') as pkl_file:\n",
    "    pickle.dump(le, pkl_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a5e726",
   "metadata": {},
   "source": [
    "## Image Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f7ca3fa",
   "metadata": {},
   "source": [
    "#### Preparing to split for train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "76d858d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = new_df[['image_path']].values \n",
    "y = new_df[['AgeRange']].values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6fdc7274",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0, 1, 2, 3}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(y.flatten().tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15281658",
   "metadata": {},
   "source": [
    "#### Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c1149349",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "670cb39e",
   "metadata": {},
   "source": [
    "#### Assigning uniform image extensions and resizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ed4b4329",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(individual_path):\n",
    "    img = tf.io.read_file(np.array(individual_path).ravel()[0]) \n",
    "    img = tf.image.decode_jpeg(img)\n",
    "    img = tf.image.resize(img, [227,227])\n",
    "    return img "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec7cbc0",
   "metadata": {},
   "source": [
    "## Face Detection and Landmark Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dbec76a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def yield_training_values(X_train,y_train):\n",
    "    detector = dlib.get_frontal_face_detector()\n",
    "    predictor = dlib.shape_predictor('shape_predictor_68_face_landmarks.dat')\n",
    "    fa = FaceAligner(predictor, desiredFaceWidth=256)\n",
    "    for image_path, value in zip(X_train, y_train):\n",
    "        imageP = image_path[0].decode(\"utf-8\")\n",
    "        img= cv2.imread(imageP, 1)\n",
    "        denoised_image = cv2.fastNlMeansDenoisingColored(img, None, 5, 6, 7, 21)\n",
    "\n",
    "        gray = cv2.cvtColor(denoised_image, cv2.COLOR_BGR2GRAY)\n",
    "        # Detect the face\n",
    "        rects = detector(gray, 1)\n",
    "        # Detect landmarks for each face\n",
    "        \n",
    "        try:\n",
    "            for rect in rects:\n",
    "                faceAligned = fa.align(img, gray, rect)\n",
    "\n",
    "            gray1 = cv2.cvtColor(faceAligned, cv2.COLOR_BGR2GRAY)\n",
    "            face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "            faces = face_cascade.detectMultiScale(gray1, 1.3, 5)\n",
    "\n",
    "            try:\n",
    "                for (x,y,w,h) in faces:\n",
    "                    # for putting rectangle on face\n",
    "                    #cv2.rectangle(faceAligned, (x,y), (x+w, y+h), (0, 255, 0),3)\n",
    "                    roi_color = faceAligned[y:y+h, x:x+w]\n",
    "                    cv2.imwrite(imageP , roi_color)\n",
    "            except:\n",
    "                continue\n",
    "        except:\n",
    "            continue\n",
    "        \n",
    "        image = preprocess_image([bytes(imageP, 'utf-8')])\n",
    "        yield image, value "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f32a38c2",
   "metadata": {},
   "source": [
    "#### Using train and test for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c0166cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = tf.data.Dataset.from_generator(yield_training_values,\n",
    "                                          args=[X_train, y_train],\n",
    "                                          output_types=(tf.float32, tf.float32),\n",
    "                                          output_shapes=([227, 227, 3], [1]))\n",
    "\n",
    "\n",
    "ds_test = tf.data.Dataset.from_generator(yield_training_values,\n",
    "                                          args=[X_test, y_test],\n",
    "                                          output_types=(tf.float32, tf.float32),\n",
    "                                          output_shapes=([227, 227, 3], [1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6c162a0",
   "metadata": {},
   "source": [
    "### Shuffling the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "702b6b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "ds_train = ds_train.cache().shuffle(buffer_size=1000).batch(32).prefetch(buffer_size=AUTOTUNE)\n",
    "ds_test = ds_test.cache().shuffle(buffer_size=1000).batch(32).prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42cb232d",
   "metadata": {},
   "source": [
    "## Model Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "362f1553",
   "metadata": {},
   "source": [
    "### Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f582d015",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = tf.keras.Sequential([\n",
    "  tf.keras.layers.RandomFlip(\"horizontal_and_vertical\"),\n",
    "  tf.keras.layers.RandomRotation(0.2),\n",
    "  tf.keras.layers.RandomZoom(0.2,0.2),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "283fd760",
   "metadata": {},
   "source": [
    "### Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cce17f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    data_augmentation,\n",
    "    keras.layers.Conv2D(filters=96, kernel_size=(7,7), strides=(4,4), activation='relu', input_shape=(227,227,3)),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2)),\n",
    "    keras.layers.Conv2D(filters=256, kernel_size=(5,5), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2)),\n",
    "    keras.layers.Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.MaxPool2D(pool_size=(3,3), strides=((2,2))),\n",
    "    keras.layers.Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.MaxPool2D(pool_size=(3,3), strides=((2,2))),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(512, activation='relu'),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(512, activation='relu', kernel_regularizer=keras.regularizers.l2(l=0.01)),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(4, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2b993d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = \"model_checkpoints_weights/imdbwiki/age_checkpoint_18jan.ckpt\"\n",
    "\n",
    "# Create a ModelCheckpoint callback that saves the model's weights only\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                         save_weights_only=True, # set to False to save the entire model\n",
    "                                                         save_best_only=True, # set to True to save only the best model instead of a model every epoch \n",
    "                                                         save_freq=\"epoch\", # save every epoch\n",
    "                                                         verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8ac08e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "#adam = tf.keras.optimizers.Adam(learning_rate=0.001) \n",
    "sgd = SGD(learning_rate=0.001)\n",
    "model.compile(optimizer=sgd, loss = tf.keras.losses.SparseCategoricalCrossentropy(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b9ab85a",
   "metadata": {},
   "source": [
    "### Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9a19e6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "   1513/Unknown - 35220s 23s/step - loss: 6.2200 - accuracy: 0.4459"
     ]
    }
   ],
   "source": [
    "history = model.fit(ds_train, validation_data=ds_test, epochs=40, callbacks = [checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b19078a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the validation and training data separately\n",
    "def plot_loss_curves(history):\n",
    "    \"\"\"\n",
    "    Returns separate loss curves for training and validation metrics.\n",
    "    \"\"\" \n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "\n",
    "    accuracy = history.history['accuracy']\n",
    "    val_accuracy = history.history['val_accuracy']\n",
    "\n",
    "    epochs = range(len(history.history['loss']))\n",
    "\n",
    "    # Plot loss\n",
    "    plt.plot(epochs, loss, label='training_loss')\n",
    "    plt.plot(epochs, val_loss, label='val_loss')\n",
    "    plt.title('Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.legend()\n",
    "\n",
    "    # Plot accuracy\n",
    "    plt.figure()\n",
    "    plt.plot(epochs, accuracy, label='training_accuracy')\n",
    "    plt.plot(epochs, val_accuracy, label='val_accuracy')\n",
    "    plt.title('Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28e5333",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"models/imdbwiki/age_26nov.h5\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47333ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss_curves(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "007659d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(ds_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d911989",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
